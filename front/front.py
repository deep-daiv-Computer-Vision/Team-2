import base64
import io
import streamlit as st
import numpy as np
import requests
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import plotly.express as px
import pandas as pd
import umap.umap_ as umap

# TODO: ë°±ì—”ë“œì™€ ì—°ê²°í•˜ëŠ” ì‘ì—… í•„ìš”

# í˜ì´ì§€ ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € í˜¸ì¶œ
st.set_page_config(
    page_title="XAIkit-learn",
    page_icon="ğŸ¤–", layout="wide"
    )

def show_importance_score(importance_score: list, segments: list, concat_indices: list):
    # ë“¤ì–´ì˜¤ê¸° ì „ì— ì´ë¯¸ theme indexì— í•´ë‹¹í•˜ëŠ” importance score, concat_indicesê°€ ë“¤ì–´ì™”ë‹¤ ê°€ì •
    whole_token = len(importance_score)
    output_list = [[] * len(segments)]

    # forë¬¸ì„ ëŒì•„ê°€ë©° concat_indices ê¸°ë°˜ í•´ë‹¹ segmentsê°€ ëª‡ ë‹¨ì–´ë¡œ ì´ë¤„ì ¸ ìˆëŠ”ì§€ í™•ì¸
    # í•´ë‹¹ ë‹¨ì–´ë§Œí¼ importance scoreì„ output_list[(segment_index)[scores]] í˜•ì‹ìœ¼ë¡œ ì €ì¥
    # importance ë˜ëŠ” concat_indicesì˜ ëì— í•´ë‹¹í•˜ë©´ ë°”ë¡œ return output_list
    current_index = 0

    for idx, seg_index in enumerate(concat_indices):
        seg_tokens = len(segments[seg_index].split(' '))

        # ì „ì²´ segmentì— í•´ë‹¹í•˜ëŠ” indicesë¥¼ ëª» ëŒì•˜ëŠ”ë° ëë‚˜ë²„ë ¸ì„ë•Œ
        if current_index + seg_tokens > whole_token:
            return idx, output_list

        output_list[seg_index].append(importance_score[current_index:current_index + seg_tokens])
        current_index += seg_tokens
    
    return -1, output_list


def create_attention_html(text, attention_scores):
    """í…ìŠ¤íŠ¸ì— attention scoreë¥¼ ì ìš©í•˜ì—¬ HTMLë¡œ ë³€í™˜"""
    words = text.split()
    
    # attention_scoresë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
    if isinstance(attention_scores, np.ndarray):
        if attention_scores.ndim > 1:
            attention_scores = attention_scores.mean(axis=tuple(range(attention_scores.ndim-1)))
    else:
        attention_scores = np.array(attention_scores).flatten()
    
    # attention_scoresì˜ ê¸¸ì´ê°€ wordsì˜ ê¸¸ì´ì™€ ë‹¤ë¥¸ ê²½ìš° ì²˜ë¦¬
    if len(attention_scores) != len(words):
        # ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ attention_scoresë¥¼ ë¦¬ìƒ˜í”Œë§
        attention_scores = np.interp(
            np.linspace(0, 1, len(words)),
            np.linspace(0, 1, len(attention_scores)),
            attention_scores
        )
    
    html = ""
    for word, score in zip(words, attention_scores):
        # ì£¼í™©ìƒ‰ í•˜ì´ë¼ì´íŠ¸ ì‚¬ìš© (255, 165, 0)
        html += f'<span style="background-color: rgba(255, 165, 0, {float(score):.2f}); color: black;">{word}</span> '
    return html

def get_summary_and_attention(text, model_name):
    """í…ìŠ¤íŠ¸ ìš”ì•½ ë° ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚°"""
    try:
        data = {'select_model': model_name}
        
        # íŒŒì¼ ì—…ë¡œë“œì¸ ê²½ìš°
        if isinstance(text, bytes) or hasattr(text, 'read'):
            files = {
                'file': ('input.txt', text if isinstance(text, bytes) else text.read(), 'text/plain')
            }
            response = requests.post(
                "http://localhost:5000/summarize",
                files=files,
                data=data
            )
        # ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥ì¸ ê²½ìš°
        else:
            data['text'] = text
            response = requests.post(
                "http://localhost:5000/summarize",
                json=data
            )
            
        if response.status_code == 200:
            result = response.json()
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ì‘ë‹µ ë‚´ìš© ì¶œë ¥
            st.write("API ì‘ë‹µ ë‚´ìš©:", result.keys())
            
            # ë°°ì¹˜ ìš”ì•½ë¬¸ê³¼ ì¤‘ìš”ë„ ì ìˆ˜ ì¶”ì¶œ
            batch_summaries = result.get('batch_summaries', [])
            batch_importances = result.get('batch_importances', [])
            segments = result.get('segments', [])
            concat_indices = result.get('concat_indices', [])
            evaluation_results = result.get('evaluation_results', {})
            
            # í† í° ì¤‘ìš”ë„ ì •ê·œí™”
            token_importance = np.array(batch_importances[0] if isinstance(batch_importances[0], list) else batch_importances)
            if token_importance.ndim > 1:
                token_importance = token_importance.mean(axis=tuple(range(token_importance.ndim-1)))
            
            token_max = np.max(token_importance)
            token_min = np.min(token_importance)
            
            if token_max == token_min:
                normalized_importance = np.full_like(token_importance, 0.5)
            else:
                normalized_importance = (token_importance - token_min) / (token_max - token_min)
            
            return {
                'summaries': batch_summaries,
                'importance_scores': normalized_importance,
                'segments': segments,
                'concat_indices': concat_indices,
                'evaluation_results': evaluation_results
            }
                
        else:
            st.error(f"API ì˜¤ë¥˜: {response.status_code}")
            return None
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def calculate_rouge(summary, reference):
    """ROUGE ì ìˆ˜ ê³„ì‚°"""
    try:
        response = requests.post(
            "http://localhost:5000/calculate-rouge",
            json={
                "summary": summary,
                "reference": reference
            }
        )
        if response.status_code == 200:
            result = response.json()
            # route.pyì—ì„œ ë°˜í™˜í•˜ëŠ” í˜•ì‹ì— ë§ì¶° ê°’ì„ ì¶”ì¶œ
            return {
                'rouge1': result['rouge-1']['f'],
                'rouge2': result['rouge-2']['f'],
                'rougeL': result['rouge-l']['f']
            }
        else:
            st.error(f"ROUGE ê³„ì‚° ì˜¤ë¥˜: {response.status_code}")
            return {
                'rouge1': 0.0,
                'rouge2': 0.0,
                'rougeL': 0.0
            }
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return {
            'rouge1': 0.0,
            'rouge2': 0.0,
            'rougeL': 0.0
        }

def calculate_bert_score(summary, reference):
    """BERTScore ê³„ì‚°"""
    try:
        response = requests.post(
            "http://localhost:5000/calculate-bertscore",
            json={
                "summary": summary,
                "reference": reference
            }
        )
        if response.status_code == 200:
            return response.json()["score"]  # float ê°’ìœ¼ë¡œ ë°˜í™˜ë¨
        else:
            st.error(f"BERTScore ê³„ì‚° ì˜¤ë¥˜: {response.status_code}")
            return 0.0
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return 0.0

def get_resummarize(full_text, target_text):
    """ì„ íƒëœ ë¬¸ì¥ì— ëŒ€í•œ ì¬ìš”ì•½ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.post(
            "http://localhost:5000/resummarize",
            json={
                "full_text": full_text,
                "target_text": target_text
            }
        )
        if response.status_code == 200:
            result = response.json()
            # ì²« ë²ˆì§¸ ì‹¤í—˜ ê²°ê³¼ë§Œ ë°˜í™˜
            return result if result else None
        else:
            st.error(f"ì¬ìš”ì•½ API ì˜¤ë¥˜: {response.status_code}")
            return None
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def calculate_sentence_similarity(sentence1, sentence2_list):
    """ë¬¸ì¥ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # ë¬¸ì¥ ì„ë² ë”© ê³„ì‚°
    embedding1 = model.encode([sentence1], convert_to_tensor=True)
    embedding2 = model.encode(sentence2_list, convert_to_tensor=True)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(
        embedding1.cpu().numpy(),
        embedding2.cpu().numpy()
    )[0]
    
    return similarities

def create_cluster_visualization(segments, concat_indices):
    """segmentsë¥¼ UMAPìœ¼ë¡œ ì‹œê°í™”"""
    try:
        # ë¬¸ì¥ ì„ë² ë”© ìƒì„±
        model = SentenceTransformer('all-MiniLM-L6-v2')
        embeddings = model.encode(segments)
        
        # UMAPìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ
        reducer = umap.UMAP(
            n_components=2,
            random_state=42,
            n_neighbors=15,
            min_dist=0.1,
            metric='cosine'
        )
        embeddings_2d = reducer.fit_transform(embeddings)
        
        # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ìƒì„±
        cluster_labels = [-1] * len(segments)
        for cluster_id, indices in enumerate(concat_indices):
            for idx in indices:
                cluster_labels[idx] = cluster_id
        
        # DataFrame ìƒì„±
        df = pd.DataFrame({
            'x': embeddings_2d[:, 0],
            'y': embeddings_2d[:, 1],
            'cluster': [f'Cluster {l}' if l != -1 else 'Unclustered' for l in cluster_labels],
            'text': segments
        })
        
        # Plotlyë¡œ ì‹œê°í™”
        fig = px.scatter(
            df, x='x', y='y',
            color='cluster',
            hover_data=['text'],
            title='Sentence Clusters Visualization (UMAP)'
        )
        
        # ë ˆì´ì•„ì›ƒ ì¡°ì • - í¬ê¸° ì¶•ì†Œ
        fig.update_layout(
            plot_bgcolor='white',
            width=600,  # 800 -> 600
            height=400  # 500 -> 400
        )
        
        return fig
    
    except Exception as e:
        st.error(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

def main():
    # íŒì—… ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ session state ì´ˆê¸°í™”
    if 'popup_states' not in st.session_state:
        st.session_state.popup_states = {}
    
    # selected_sentence ì´ˆê¸°í™”
    if 'selected_sentence' not in st.session_state:
        st.session_state.selected_sentence = None
        
    # model_result ì´ˆê¸°í™”
    if 'model_result' not in st.session_state:
        st.session_state.model_result = None

    # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown("""
        <style>
        .text-section {
            position: relative;
            margin: 10px 0;
        }
        .summary-box {
            background-color: white;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-top: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        </style>
        """, unsafe_allow_html=True)

    st.title("ğŸ”®ğŸ’¯ì‹œí—˜ ê³µë¶€ ë²¼ë½ì¹˜ê¸° ì‹œíŠ¸ ë§Œë“¤ê¸°")
    st.write("ë³¸ ìš”ì•½ì‹œìŠ¤í…œì€ ì˜ì–´ ìš”ì•½ë§Œ ì œê³µí•©ë‹ˆë‹¤.")
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ê°•ì˜ ë‚´ìš© ìš”ì•½í•˜ê¸°")
    # ì…ë ¥ ë°©ì‹ ì„ íƒ
    input_type = st.sidebar.segmented_control(
        label="ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”",
        options=["íŒŒì¼ ì—…ë¡œë“œ", "ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥"],
        default="íŒŒì¼ ì—…ë¡œë“œ"
    )
    
    # ì…ë ¥ ì„¹ì…˜
    st.sidebar.header("Input Section")
    text_input = None
    
    if input_type == "íŒŒì¼ ì—…ë¡œë“œ":
        uploaded_file = st.sidebar.file_uploader(
            "ìš”ì•½í•  í…ìŠ¤íŠ¸ íŒŒì¼(.txt)ì„ ì—…ë¡œë“œ í•˜ì„¸ìš”.",
            type=['txt'],
            help="ìµœëŒ€ 200MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
        
        # TODO: ê°œë°œ ì–´ëŠì •ë„ ëë‚˜ë©´ ì´ ë¶€ë¶„ ì‚­ì œ
        if uploaded_file is not None:
            file_details = {
                "íŒŒì¼ëª…": uploaded_file.name,
                "íŒŒì¼í¬ê¸°": f"{uploaded_file.size / 1024:.2f} KB",
                "íŒŒì¼íƒ€ì…": uploaded_file.type
            }
            st.sidebar.write("### íŒŒì¼ ì •ë³´")
            st.sidebar.json(file_details)
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            text_input = uploaded_file.getvalue().decode('utf-8')
            
    else:
        text_input = st.sidebar.text_area(
            "ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            height=180,
            placeholder="ì—¬ê¸°ì— ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
        )

    # êµ¬ë¶„ì„  ì¶”ê°€
    st.sidebar.divider()
    
    # ìš”ì•½ ëª¨ë¸ ì„ íƒ ì„¹ì…˜
    st.sidebar.header("Summarization Model")
    
    # ëª¨ë¸ ì„¤ì •
    model_name = st.sidebar.selectbox(
        "ìš”ì•½ ëª¨ë¸ ì„ íƒ:",
        ["facebook/bart-large-cnn", "google/pegasus-xsum", "t5-base"],
        # TODO: ìš”ì•½ëª¨ë¸ ìµœì¢… í™•ì¸ í•„ìš”, bart-large-cnn ë¹¼ê³  ì •í•œê²Œ ìˆë‚˜..?
        index=0  # facebook/bart-large-cnnì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
    )
    
    # ë©”ì¸ ì˜ì—­ ì„¤ì •
    col1, col2 = st.columns(2)

    image_ = None
    
    # ìš”ì•½ ë²„íŠ¼
    if st.sidebar.button("ìš”ì•½í•˜ê¸°", type="primary"):
        if text_input:
            with st.spinner("ìš”ì•½ ì¤‘..."):
                # ì‹¤ì œ ìš”ì•½ ë° ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚°
                model_result = get_summary_and_attention(text_input, model_name)
                
                if model_result is not None:  # None ì²´í¬ ì¶”ê°€
                    # session_stateì— ê²°ê³¼ ì €ì¥
                    st.session_state.model_result = model_result
                    st.session_state.summary = model_result['summaries']
                    st.session_state.attention_scores = model_result['importance_scores']
                    st.session_state.text_input = text_input
                    
                    # ROUGEì™€ BERTScore ê³„ì‚° ë° í‘œì‹œ
                    evaluation_scores = model_result['evaluation_results']
                    
                    # ì‚¬ì´ë“œë°”ì— í‰ê°€ ì ìˆ˜ í‘œì‹œ
                    st.sidebar.divider()
                    st.sidebar.header("í‰ê°€ ê²°ê³¼")
                    
                    # ROUGE ì ìˆ˜
                    st.sidebar.write("#### ROUGE ì ìˆ˜")
                    col1_rouge, col2_rouge = st.sidebar.columns(2)
                    with col1_rouge:
                        st.metric("ROUGE-1", f"{evaluation_scores['rouge1']:.3f}")
                        st.metric("ROUGE-2", f"{evaluation_scores['rouge2']:.3f}")
                    with col2_rouge:
                        st.metric("ROUGE-L", f"{evaluation_scores['rougeL']:.3f}")
                    
                    # BERT ì ìˆ˜
                    st.sidebar.write("#### BERT ì ìˆ˜")
                    st.sidebar.metric("BERTScore", f"{evaluation_scores['bert_score']:.3f}")

    # session_stateì— ì €ì¥ëœ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
    if 'summary' in st.session_state:
        with col1:
            st.header("ìš”ì•½ ê²°ê³¼")
            view_mode = st.segmented_control(
                label="ë³´ê¸° ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
                options=["ì „ì²´ ë¬¸ì¥", "íŠ¹ì • ì£¼ì œ"],
                default="ì „ì²´ ë¬¸ì¥"
            )
            
            if view_mode == "íŠ¹ì • ì£¼ì œ":
                if st.session_state.model_result is not None:
                    # UMAP ì‹œê°í™”
                    segments = st.session_state.model_result.get('segments', [])
                    concat_indices = st.session_state.model_result.get('concat_indices', [])
                    
                    if segments and concat_indices:
                        fig = create_cluster_visualization(segments, concat_indices)
                        if fig is not None:
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # ìš”ì•½ ë¬¸ì¥ë“¤ì„ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ
                        summary_sentences = st.session_state.get('summary', [])
                        for i, sent in enumerate(summary_sentences):
                            if sent:  # ë¹ˆ ë¬¸ì¥ ì œì™¸
                                if st.button(f"{sent}.", key=f"topic_summary_sent_{i}"):
                                    if st.session_state.popup_states.get(i, False):
                                        st.session_state.popup_states[i] = False
                                        st.session_state.selected_sentence = None
                                    else:
                                        st.session_state.popup_states = {k: False for k in st.session_state.popup_states.keys()}
                                        st.session_state.popup_states[i] = True
                                        st.session_state.selected_sentence = sent
                                        
                                        # ì¬ìš”ì•½ ìˆ˜í–‰
                                        if st.session_state.text_input:
                                            with st.spinner("ì¬ìš”ì•½ ì¤‘..."):
                                                result = get_resummarize(
                                                    st.session_state.text_input,
                                                    sent
                                                )
                                                if result:
                                                    st.markdown("#### ì¬ìš”ì•½ ê²°ê³¼")
                                                    st.write(result)
                    else:
                        st.info("í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            elif view_mode == "ì „ì²´ ë¬¸ì¥":
                st.info("""
                ğŸ’¡ **ì „ì²´ ë¬¸ì¥ ëª¨ë“œ ì„¤ëª…ì„œ**
                - ì˜†ì— ë‚˜ì˜¨ ì›ë¬¸ í…ìŠ¤íŠ¸ì˜ ìƒ‰ê¹”ì€ ìš”ì•½ ëª¨ë¸ì´ ì–´ë””ë¥¼ ì§‘ì¤‘í–ˆëŠ”ì§€ ì‹œê°í™”í•œ ëª¨ìŠµì…ë‹ˆë‹¤.
                """)
                # ìš”ì•½ ë¬¸ì¥ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì³ì„œ í‘œì‹œ
                summary_text = " ".join(st.session_state['summary']) if isinstance(st.session_state['summary'], list) else st.session_state['summary']
                st.markdown(
                    f"""
                    <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px;">
                        {summary_text}
                    </div>
                    """,
                    unsafe_allow_html=True
                )
            else:
                pass

        with col2:
            st.header("ì›ë³¸ í…ìŠ¤íŠ¸")
            if view_mode == "ì „ì²´ ë¬¸ì¥":
                # ê¸°ì¡´ì˜ attention score ì‹œê°í™”
                html_content = create_attention_html(st.session_state['text_input'], st.session_state['attention_scores'])
                st.markdown(
                    f"""
                    <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px;">
                        {html_content}
                    </div>
                    """,
                    unsafe_allow_html=True
                )
            else:  # "íŠ¹ì • ì£¼ì œ" ëª¨ë“œ
                if st.session_state.selected_sentence:
                    # segmentsì™€ concat_indices ê°€ì ¸ì˜¤ê¸°
                    segments = st.session_state.model_result.get('segments', [])
                    
                    if segments:
                        # ì„ íƒëœ ë¬¸ì¥ê³¼ ëª¨ë“  segmentsì˜ ìœ ì‚¬ë„ ê³„ì‚°
                        similarities = calculate_sentence_similarity(
                            st.session_state.selected_sentence,
                            segments
                        )
                        
                        # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
                        similarity_threshold = 0.5
                        
                        html_content = ""
                        for i, segment in enumerate(segments):
                            if segment:  # ë¹ˆ ë¬¸ì¥ ì œì™¸
                                similarity = similarities[i]
                                if similarity > similarity_threshold:
                                    opacity = min(similarity, 0.9)
                                    html_content += f'<span style="background-color: rgba(144, 238, 144, {opacity:.2f}); color: black;">{segment}</span> '
                                else:
                                    html_content += f'{segment} '
                        
                        st.markdown(
                            f"""
                            <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px;">
                                {html_content}
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                    else:
                        st.info("ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ìš”ì•½ ë¬¸ì¥ì„ í´ë¦­í•˜ë©´ ê´€ë ¨ëœ ì›ë³¸ ë¬¸ì¥ì´ í•˜ì´ë¼ì´íŠ¸ë©ë‹ˆë‹¤.")
            
    else:
        st.sidebar.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    # ìŠ¤íƒ€ì¼ ì„¤ì •
    st.markdown("""
        <style>
        .stButton>button {
            width: 100%;
            margin-top: 20px;
        }
        .uploadedFile {
            border: 1px solid #ccc;
            padding: 10px;
            border-radius: 5px;
        }
        </style>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()